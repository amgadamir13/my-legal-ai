import streamlit as st
import os, fitz, json, base64
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from PIL import Image # Ù„Ø¯Ø¹Ù… ØµÙˆØ± Ø§Ù„Ø£ÙŠÙÙˆÙ†

# --- 1. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© (Mobile-First) ---
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù‚Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [data-testid="stAppViewContainer"], .stApp {
        direction: rtl !important;
        text-align: right !important;
        font-family: 'Cairo', sans-serif !important;
    }
    input[type="password"] { direction: ltr !important; text-align: left !important; }
    .legal-card {
        background: white; padding: 25px; border-radius: 15px;
        border-right: 10px solid #1A73E8;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-top: 20px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù€ PDF (OCR Engine) ---
@st.cache_resource
def load_rag_engine():
    return SentenceTransformer('all-MiniLM-L6-v2')

embed_model = load_rag_engine()
DOCS_PATH = "documents"

@st.cache_data
def process_all_files():
    meta, texts = [], []
    if not os.path.exists(DOCS_PATH): os.makedirs(DOCS_PATH)
    
    # Ù‚Ø±Ø§Ø¡Ø© ÙƒØ§ÙØ© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª (PDF + ØµÙˆØ±)
    supported_extensions = ('.pdf', '.png', '.jpg', '.jpeg', '.heic')
    files = [f for f in os.listdir(DOCS_PATH) if f.lower().endswith(supported_extensions)]
    
    if not files: return None, None

    for f in files:
        path = os.path.join(DOCS_PATH, f)
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù„Ù PDF
        if f.lower().endswith('.pdf'):
            try:
                with fitz.open(path) as doc:
                    for i, page in enumerate(doc):
                        content = page.get_text().strip()
                        if content:
                            meta.append({"file": f, "page": i+1, "text": content})
                            texts.append(content)
            except: continue
        # Ø¥Ø°Ø§ ÙƒØ§Ù† ØµÙˆØ±Ø© (JPG/PNG) - Ù†Ø­ØªØ§Ø¬ Ù„Ù€ Gemini Ù„Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØµÙ‡Ø§
        else:
            meta.append({"file": f, "page": "ØµÙˆØ±Ø©", "text": f"Ù…Ø±ÙÙ‚ ØµÙˆØ±Ø© Ø¨Ø§Ø³Ù… {f}"})
            texts.append(f"Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ØµÙˆØ±Ø© Ù„Ù…Ø³ØªÙ†Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨Ø§Ø³Ù… {f}")
            
    if not texts: return None, None
    idx = faiss.IndexFlatL2(embed_model.encode(texts).shape[1])
    idx.add(np.array(embed_model.encode(texts)).astype('float32'))
    return idx, meta

vector_index, doc_library = process_all_files()

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.markdown('<center><img src="https://www.gstatic.com/lamda/images/gemini_sparkle_v002.svg" width="50"></center>', unsafe_allow_html=True)
st.markdown("<h2 style='text-align: center;'>Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ (PDF + ØµÙˆØ±)</h2>", unsafe_allow_html=True)

api_key = st.text_input("Gemini API Key (Secret)", type="password")

with st.expander("ğŸ“‚ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙˆØ§Ù„ØµÙˆØ±"):
    if vector_index:
        st.success(f"ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ {len(doc_library)} Ø¹Ù†ØµØ± (PDF ÙˆØµÙˆØ±)")
    else:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù€ PDF ÙÙŠ Ù…Ø¬Ù„Ø¯ documents")

u_query = st.text_area("Ø£Ø¯Ø®Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ:", height=150)
analyze = st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ø¢Ù† âš–ï¸")

# --- 4. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬ (Multi-Modal) ---
if analyze and api_key:
    genai.configure(api_key=api_key)
    try:
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Pro ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙˆØ±)
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§..."):
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
            q_vec = embed_model.encode([u_query])
            D, I = vector_index.search(np.array(q_vec).astype('float32'), k=5)
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØµÙˆØ± Ù„Ù„ØªØ­Ù„ÙŠÙ„
            context_text = ""
            images_to_process = []
            
            for idx in I[0]:
                if idx != -1:
                    m = doc_library[idx]
                    if "ØµÙˆØ±Ø©" in str(m['page']):
                        img_path = os.path.join(DOCS_PATH, m['file'])
                        images_to_process.append(Image.open(img_path))
                    context_text += f"\n[Ø§Ù„Ù…ØµØ¯Ø±: {m['file']}, {m['page']}]\n{m['text']}\n"

            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ Gemini (Ù†Øµ + ØµÙˆØ±)
            prompt = f"""
            Ø¨ØµÙØªÙƒ Ø®Ø¨ÙŠØ±Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø©.
            Ù…Ù‡Ù…ØªÙƒ:
            1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø´ÙˆÙ‡Ø© ÙÙŠ Ø§Ù„ØµÙˆØ± ÙˆØªØ±Ù…ÙŠÙ…Ù‡Ø§ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹.
            2. ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©.
            3. ØªØ­Ø¯ÙŠØ¯ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ£Ø³Ù…Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØ± Ø¨Ø¯Ù‚Ø©.
            
            Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬: {context_text}
            Ø§Ù„Ø³Ø¤Ø§Ù„: {u_query}
            """
            
            # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª ØµÙˆØ±ØŒ Ù†Ø±Ø³Ù„Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ù†Øµ
            if images_to_process:
                response = model.generate_content([prompt] + images_to_process)
            else:
                response = model.generate_content(prompt)
            
            st.markdown(f'<div class="legal-card">{response.text}</div>', unsafe_allow_html=True)
            
    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {str(e)}")
