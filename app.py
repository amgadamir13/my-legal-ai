import streamlit as st
import os, fitz, base64
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from PIL import Image

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®ØµÙˆØµÙŠØ© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© (RTL) ---
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù‚Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [data-testid="stAppViewContainer"], .stApp {
        direction: rtl !important;
        text-align: right !important;
        font-family: 'Cairo', sans-serif !important;
    }
    input[type="password"] { direction: ltr !important; text-align: left !important; }
    .legal-card {
        background: white; padding: 25px; border-radius: 15px;
        border-right: 10px solid #1A73E8;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-top: 20px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØµÙˆØ± ---
@st.cache_resource
def load_ai_engine():
    return SentenceTransformer('all-MiniLM-L6-v2')

embed_model = load_ai_engine()
DOCS_DIR = "documents"

@st.cache_data
def load_all_documents():
    meta, texts = [], []
    if not os.path.exists(DOCS_DIR): os.makedirs(DOCS_DIR)
    valid_files = [f for f in os.listdir(DOCS_DIR) if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
    if not valid_files: return None, None

    for f in valid_files:
        path = os.path.join(DOCS_DIR, f)
        if f.lower().endswith('.pdf'):
            try:
                with fitz.open(path) as doc:
                    for i, page in enumerate(doc):
                        t = page.get_text().strip()
                        if t:
                            meta.append({"file": f, "page": i+1, "text": t, "type": "pdf"})
                            texts.append(t)
            except: continue
        else:
            meta.append({"file": f, "page": "ØµÙˆØ±Ø© Ø§Ù„ØªÙ‚Ø·Øª Ø¨Ø§Ù„Ø£ÙŠÙÙˆÙ†", "text": f"Ù…Ø³ØªÙ†Ø¯ ØµÙˆØ±ÙŠ: {f}", "type": "image"})
            texts.append(f"ØµÙˆØ±Ø© Ù…Ø³ØªÙ†Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ: {f}")
            
    if not texts: return None, None
    idx = faiss.IndexFlatL2(embed_model.encode(texts).shape[1])
    idx.add(np.array(embed_model.encode(texts)).astype('float32'))
    return idx, meta

vector_index, library = load_all_documents()

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ---
st.markdown('<center><img src="https://www.gstatic.com/lamda/images/gemini_sparkle_v002.svg" width="60"></center>', unsafe_allow_html=True)
st.markdown("<h2 style='text-align: center;'>Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ</h2>", unsafe_allow_html=True)

# Ø®Ø§Ù†Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠØ© - Ø§Ø¶ØºØ· Done ÙÙŠ Ø§Ù„ÙƒÙŠØ¨ÙˆØ±Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„Ù„ØµÙ‚
api_key = st.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„Ø³Ø±ÙŠ (Secret Key) Ù‡Ù†Ø§:", type="password", help="Ù‚Ù… Ø¨Ù„ØµÙ‚ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ø¶ØºØ· Done")

if api_key:
    st.success("âœ… ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…ÙØªØ§Ø­. Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù†.")
else:
    st.info("ğŸ’¡ Ø§Ù„ØµÙ‚ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ø¨Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø¨Ø¯Ø¡.")

with st.expander("ğŸ“‚ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª"):
    if vector_index:
        st.write(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(library)} Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­.")
    else:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯ documents.")

u_query = st.text_area("Ù…Ø§ Ù‡Ùˆ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØŸ", height=150)

# Ø²Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ - Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø²Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„ØªÙ†ÙÙŠØ°
if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ù„Ø© âš–ï¸", use_container_width=True):
    if not api_key:
        st.error("ÙŠØ¬Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        genai.configure(api_key=api_key)
        try:
            # --- Ù…ÙŠØ²Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­ ---
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            # Ù†Ø®ØªØ§Ø± Ù…ÙˆØ¯ÙŠÙ„ 1.5 pro Ø¥Ø°Ø§ ÙˆØ¬Ø¯ØŒ ÙˆØ¥Ù„Ø§ Ù†Ø®ØªØ§Ø± Ø£ÙˆÙ„ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­
            model_id = next((m for m in available_models if '1.5-pro' in m), 
                           next((m for m in available_models if '1.5' in m), available_models[0]))
            
            model = genai.GenerativeModel(model_id)
            
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§..."):
                q_vec = embed_model.encode([u_query])
                D, I = vector_index.search(np.array(q_vec).astype('float32'), k=5)
                
                context_text = ""
                images = []
                for idx in I[0]:
                    if idx != -1:
                        m = library[idx]
                        if m['type'] == "image":
                            img_path = os.path.join(DOCS_DIR, m['file'])
                            images.append(Image.open(img_path))
                        context_text += f"\n[Ø§Ù„Ù…Ø³ØªÙ†Ø¯: {m['file']}, {m['page']}]\n{m['text']}\n"

                prompt = f"Ø­Ù„Ù„ ÙƒØ®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆØ¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ù„Ø£Ø¯Ù„Ø©: {context_text}\nØ§Ù„Ø³Ø¤Ø§Ù„: {u_query}"
                
                if images:
                    response = model.generate_content([prompt] + images)
                else:
                    response = model.generate_content(prompt)
                
                st.markdown("---")
                st.markdown(f'<div class="legal-card">{response.text}</div>', unsafe_allow_html=True)
                
        except Exception as e:
            st.error(f"ØªÙ†Ø¨ÙŠÙ‡: {str(e)}")
