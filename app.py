import streamlit as st
import os, fitz, json, base64
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from PIL import Image

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…Ø¸Ù‡Ø± (RTL ÙƒØ§Ù…Ù„) ---
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù‚Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [data-testid="stAppViewContainer"], .stApp {
        direction: rtl !important;
        text-align: right !important;
        font-family: 'Cairo', sans-serif !important;
    }
    /* Ø¬Ø¹Ù„ Ø®Ø§Ù†Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø®ÙÙŠØ© ÙˆØ¢Ù…Ù†Ø© */
    input[type="password"] { direction: ltr !important; text-align: left !important; }
    
    .report-card {
        background: white; padding: 20px; border-radius: 15px;
        border-right: 10px solid #1A73E8;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-top: 20px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØµÙˆØ± ---
@st.cache_resource
def load_ai_engine():
    return SentenceTransformer('all-MiniLM-L6-v2')

embed_model = load_ai_engine()
DOCS_DIR = "documents"

@st.cache_data
def load_all_documents():
    meta, texts = [], []
    if not os.path.exists(DOCS_DIR): os.makedirs(DOCS_DIR)
    
    # Ø¯Ø¹Ù… Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù€ PDF
    valid_files = [f for f in os.listdir(DOCS_DIR) if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
    
    if not valid_files: return None, None

    for f in valid_files:
        path = os.path.join(DOCS_DIR, f)
        if f.lower().endswith('.pdf'):
            try:
                with fitz.open(path) as doc:
                    for i, page in enumerate(doc):
                        t = page.get_text().strip()
                        if t:
                            meta.append({"file": f, "page": i+1, "text": t, "type": "pdf"})
                            texts.append(t)
            except: continue
        else:
            # ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØ± Ù„ÙŠÙ‚ÙˆÙ… Gemini Ø¨Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
            meta.append({"file": f, "page": "ØµÙˆØ±Ø© Ø§Ù„ØªÙ‚Ø·Øª Ø¨Ø§Ù„Ø£ÙŠÙÙˆÙ†", "text": f"Ù…Ø³ØªÙ†Ø¯ ØµÙˆØ±ÙŠ: {f}", "type": "image"})
            texts.append(f"ØµÙˆØ±Ø© Ù…Ø³ØªÙ†Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ: {f}")
            
    if not texts: return None, None
    idx = faiss.IndexFlatL2(embed_model.encode(texts).shape[1])
    idx.add(np.array(embed_model.encode(texts)).astype('float32'))
    return idx, meta

vector_index, library = load_all_documents()

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø¨Ø³ÙŠØ·Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠ Ø§Ù„Ø£ÙŠÙÙˆÙ†) ---
st.markdown('<center><img src="https://www.gstatic.com/lamda/images/gemini_sparkle_v002.svg" width="60"></center>', unsafe_allow_html=True)
st.markdown("<h2 style='text-align: center;'>Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ</h2>", unsafe_allow_html=True)

# Ø®Ø§Ù†Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠØ© - Ù„Ù† ÙŠØ¸Ù‡Ø± Ù…Ø§ ØªÙƒØªØ¨Ù‡
api_key = st.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„Ø³Ø±ÙŠ Ù‡Ù†Ø§ (Gemini API Key):", type="password")

if not api_key:
    st.info("ğŸ’¡ ÙŠØ±Ø¬Ù‰ ÙˆØ¶Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ù†Ø© Ø£Ø¹Ù„Ø§Ù‡ Ù„Ù„Ø¨Ø¯Ø¡.")
else:
    st.success("âœ… Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ØªØµÙ„. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„.")

with st.expander("ğŸ“‚ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©"):
    if vector_index:
        st.write(f"ØªÙ… ÙØ­Øµ {len(library)} Ù…Ù„ÙØ§Øª ÙˆØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­.")
    else:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØµÙˆØ± Ø£Ùˆ Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯ documents.")

u_query = st.text_area("Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§ØªØŸ", height=150, placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

# Ø§Ù„Ø²Ø± Ø§Ù„ÙƒØ¨ÙŠØ± Ù„Ù„ØªØ­Ù„ÙŠÙ„
if st.button("Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ âš–ï¸", use_container_width=True):
    if not api_key:
        st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        genai.configure(api_key=api_key)
        try:
            model = genai.GenerativeModel('gemini-1.5-pro')
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ..."):
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
                q_vec = embed_model.encode([u_query])
                D, I = vector_index.search(np.array(q_vec).astype('float32'), k=5)
                
                context_text = ""
                images = []
                
                for idx in I[0]:
                    if idx != -1:
                        m = library[idx]
                        if m['type'] == "image":
                            img_path = os.path.join(DOCS_DIR, m['file'])
                            images.append(Image.open(img_path))
                        context_text += f"\n[Ø§Ù„Ù…Ø³ØªÙ†Ø¯: {m['file']}, {m['page']}]\n{m['text']}\n"

                # Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ "ÙÙ‡Ù…" Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØ±Ù…ÙŠÙ…
                prompt = f"Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªØ§Ù„ÙŠØ© ÙƒØ®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆØ¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ù„Ø³ÙŠØ§Ù‚: {context_text}\nØ§Ù„Ø³Ø¤Ø§Ù„: {u_query}"
                
                if images:
                    response = model.generate_content([prompt] + images)
                else:
                    response = model.generate_content(prompt)
                
                st.markdown("---")
                st.markdown(f'<div class="report-card">{response.text}</div>', unsafe_allow_html=True)
                
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ø£Ùˆ Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª. (Ø§Ù„ØªÙØ§ØµÙŠÙ„: {str(e)})")
