import streamlit as st
import os, fitz, json, base64
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# --- 1. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (RTL Ù„Ù„Ø¹Ø±Ø¨ÙŠ Ùˆ LTR Ù„Ù„ÙƒÙˆØ¯) ---
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù‚Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø¹Ø§Ù… - Ø¹Ø±Ø¨ÙŠ */
    html, body, [data-testid="stAppViewContainer"], .main, .stApp {
        direction: rtl !important;
        text-align: right !important;
        font-family: 'Cairo', sans-serif !important;
    }

    /* Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø®Ø§Øµ Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù…ÙˆØ² Ø£Ùˆ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù„ØªØ¸Ù„ LTR */
    input[type="password"], input[type="text"] {
        direction: ltr !important;
        text-align: left !important;
    }

    /* Ø­Ø§ÙˆÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© */
    .legal-card {
        background: #ffffff;
        padding: 20px;
        border-radius: 12px;
        border-right: 8px solid #1A73E8;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        color: #1a1a1a;
        margin-top: 20px;
    }

    /* Ø²Ø± Ø§Ù„ØªØ´ØºÙŠÙ„ - Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø¥Ø¨Ù‡Ø§Ù… Ø§Ù„ÙŠØ¯ ÙÙŠ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ */
    .stButton > button {
        width: 100%;
        border-radius: 50px;
        height: 3.5em;
        background: #1A73E8;
        color: white;
        font-weight: bold;
        border: none;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ‚Ù†ÙŠ ---
@st.cache_resource
def setup_ai():
    return SentenceTransformer('all-MiniLM-L6-v2')

embed_model = setup_ai()
DOCS_PATH = "documents"

@st.cache_data
def process_docs():
    meta, texts = [], []
    if not os.path.exists(DOCS_PATH): os.makedirs(DOCS_PATH)
    files = [f for f in os.listdir(DOCS_PATH) if f.lower().endswith(".pdf")]
    if not files: return None, None
    for f in files:
        path = os.path.join(DOCS_PATH, f)
        try:
            with fitz.open(path) as doc:
                for i, page in enumerate(doc):
                    content = page.get_text().strip()
                    if content:
                        meta.append({"file": f, "page": i+1, "text": content})
                        texts.append(content)
        except: continue
    if not texts: return None, None
    embeddings = embed_model.encode(texts)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings).astype('float32'))
    return index, meta

vector_index, doc_library = process_docs()

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ---
st.markdown('<center><img src="https://www.gstatic.com/lamda/images/gemini_sparkle_v002.svg" width="50"></center>', unsafe_allow_html=True)
st.markdown("<h2 style='text-align: center;'>Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ</h2>", unsafe_allow_html=True)

# Ø®Ø§Ù†Ø© Ø§Ù„Ù…ÙØªØ§Ø­ (Ø³ØªØ¸Ù‡Ø± LTR ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù…Ù†Ø¹ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³)
api_key = st.text_input("Gemini API Key (Secret)", type="password", help="Ø£Ø¯Ø®Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø±ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù‡Ù†Ø§")

with st.expander("ğŸ“‚ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"):
    if vector_index:
        st.success(f"ØªÙ…Øª Ø£Ø±Ø´ÙØ© {len(doc_library)} ØµÙØ­Ø©")
    else:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª PDF")
    if st.button("ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        st.cache_data.clear()
        st.rerun()

u_query = st.text_area("Ù…Ø§ Ù‡Ùˆ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØŸ", height=120)
analyze = st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø¢Ù† âš–ï¸")

# --- 4. Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø°ÙƒÙŠ ---
if analyze and api_key:
    genai.configure(api_key=api_key)
    try:
        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­ Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ 404
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target = 'models/gemini-1.5-pro' if 'models/gemini-1.5-pro' in available_models else available_models[0]
        
        model = genai.GenerativeModel(target)
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¯Ù„Ø©..."):
            # Ø¨Ø­Ø« Ø³ÙŠÙ…Ø§Ù†ØªÙƒ (Ø¨Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯)
            q_vec = embed_model.encode([u_query])
            D, I = vector_index.search(np.array(q_vec).astype('float32'), k=5)
            
            context = ""
            for idx in I[0]:
                if idx != -1:
                    m = doc_library[idx]
                    context += f"\n[Ø§Ù„Ù…ØµØ¯Ø±: {m['file']}, Øµ.{m['page']}]\n{m['text'][:800]}\n"

            prompt = f"Ø­Ù„Ù„ ÙƒØ®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ ÙˆØ¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ù„Ø³ÙŠØ§Ù‚: {context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {u_query}"
            response = model.generate_content(prompt)
            
            st.markdown(f'<div class="legal-card">{response.text}</div>', unsafe_allow_html=True)
            
    except Exception as e:
        st.error(f"ØªÙ†Ø¨ÙŠÙ‡: {str(e)}")
